{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 random labels that're either 0 or 1\n",
    "y_true = np.random.randint(0,2, size=5)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Classifier that always predict label 1\n",
    "y_pred = np.ones(5, dtype=np.int32)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the accuracy of our prediction?   \n",
    "accuracy = # correctly predicted / total # of data points   \n",
    "accuracy = 1 / 5 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20000000000000001"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_true == y_pred) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 1 and Type 2 Errors\n",
    "- If we predict positive but data point is negative => false positive => type 1 errors\n",
    "- If we predict negative but data point is positive => false negative => type 2 errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive data points:  [False False False False  True]\n",
      "Predicted positives:  [ True  True  True  True  True]\n",
      "# of true positives:  1\n",
      "# of false positives:  4\n"
     ]
    }
   ],
   "source": [
    "# Calculating type 1 and type 2 errors\n",
    "positive_data_points = (y_true == 1)\n",
    "predicted_positives = (y_pred == 1)\n",
    "print('Positive data points: ', positive_data_point)\n",
    "print('Predicted positives: ', predicted_positives)\n",
    "true_positive = np.sum(predicted_positives * positive_data_points)\n",
    "print('# of true positives: ', true_positive)\n",
    "\n",
    "false_positives = np.sum((y_true != 1) * (y_pred == 1))\n",
    "print('# of false positives: ', false_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate true negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of true negatives =  0\n"
     ]
    }
   ],
   "source": [
    "true_negatives = np.sum((y_true != 1) * (y_pred != 1))\n",
    "print('# of true negatives = ', true_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify accuracy   \n",
    "accuracy = (# of true negatives + # of true positives) / # of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "accuracy = (true_negatives + true_positive) / y_true.size\n",
    "print('Accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Precision   \n",
    "precision = true positives / (true positives + false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.2\n"
     ]
    }
   ],
   "source": [
    "precision = true_positive / (true_positive + false_positives)\n",
    "print('Precision = ', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify our precision using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Recall\n",
    "Recall - fraction of all positives that we correctly classified as positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall =  1.0\n"
     ]
    }
   ],
   "source": [
    "false_negative = np.sum((y_pred != 1) * (y_true == 1))\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "print('Recall = ', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
